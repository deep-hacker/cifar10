{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "import scipy\n",
    "from scipy import misc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
    "y_train = np.squeeze(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet',include_top = False, input_shape = (64,64,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain bottleneck features for train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottleneck features detected train\n",
      "bottleneck features saved for train\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('vgg16_features_train.npz'):\n",
    "    print('bottleneck features detected train')\n",
    "    features = np.load('vgg16_features_train.npz')['features']\n",
    "else:\n",
    "    print('bottleneck features are calculated now')\n",
    "    big_x_train = np.array([scipy.misc.imresize(x_train[i], (64, 64, 3)) \n",
    "                            for i in range(0, len(x_train))]).astype('float32')\n",
    "    vgg16_input_train = preprocess_input(big_x_train)\n",
    "    print('train data preprocessed')\n",
    "    features = model.predict(vgg16_input_train)\n",
    "    np.savez('vgg16_features_train',features = features)\n",
    "print('bottleneck features saved for train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain bottleneck features for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottleneck features detected test\n",
      "bottleneck features saved for test\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('vgg16_features_test.npz'):\n",
    "    print('bottleneck features detected test')\n",
    "    features_test = np.load('vgg16_features_test.npz')['features_test']\n",
    "else:\n",
    "    print('bottleneck features are calculated now')\n",
    "    big_x_test = np.array([scipy.misc.imresize(x_test[i], (64, 64, 3)) \n",
    "                       for i in range(0, len(x_test))]).astype('float32')\n",
    "    vgg16_input_test = preprocess_input(big_x_test)\n",
    "    print('test data preprocessed')\n",
    "    features_test = model.predict(vgg16_input_test)\n",
    "    np.savez('vgg16_features_test',features_test = features_test)\n",
    "print('bottleneck features saved for test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "9\n",
      "9\n",
      "4\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "number_of_labels = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train,num_classes=number_of_labels)\n",
    "y_test = to_categorical(y_test,num_classes=number_of_labels)\n",
    "for i in range(5):\n",
    "    print(y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 500)               1024500   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 1,280,010\n",
      "Trainable params: 1,280,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(2,2,512)))\n",
    "model.add(Dense(500, activation= 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(500, activation= 'relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "42500/42500 [==============================] - 22s 529us/step - loss: 2.3126 - acc: 0.6091 - val_loss: 0.8426 - val_acc: 0.7239\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.84261, saving model to weights_Transfer_learning.best.hdf5\n",
      "Epoch 2/10\n",
      "42500/42500 [==============================] - 23s 543us/step - loss: 0.9382 - acc: 0.7179 - val_loss: 0.7773 - val_acc: 0.7495\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.84261 to 0.77731, saving model to weights_Transfer_learning.best.hdf5\n",
      "Epoch 3/10\n",
      "42500/42500 [==============================] - 27s 642us/step - loss: 0.8461 - acc: 0.7421 - val_loss: 0.7354 - val_acc: 0.7616\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.77731 to 0.73536, saving model to weights_Transfer_learning.best.hdf5\n",
      "Epoch 4/10\n",
      "42500/42500 [==============================] - 25s 596us/step - loss: 0.7988 - acc: 0.7636 - val_loss: 0.7396 - val_acc: 0.7661\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.73536\n",
      "Epoch 5/10\n",
      "42500/42500 [==============================] - 23s 538us/step - loss: 0.7624 - acc: 0.7764 - val_loss: 0.7095 - val_acc: 0.7775\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.73536 to 0.70949, saving model to weights_Transfer_learning.best.hdf5\n",
      "Epoch 6/10\n",
      "42500/42500 [==============================] - 25s 592us/step - loss: 0.7295 - acc: 0.7924 - val_loss: 0.7022 - val_acc: 0.7843\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.70949 to 0.70223, saving model to weights_Transfer_learning.best.hdf5\n",
      "Epoch 7/10\n",
      "42500/42500 [==============================] - 23s 551us/step - loss: 0.6879 - acc: 0.8030 - val_loss: 0.6815 - val_acc: 0.7956\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.70223 to 0.68152, saving model to weights_Transfer_learning.best.hdf5\n",
      "Epoch 8/10\n",
      "42500/42500 [==============================] - 25s 581us/step - loss: 0.6482 - acc: 0.8182 - val_loss: 0.7045 - val_acc: 0.7956\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.68152\n",
      "Epoch 9/10\n",
      "42500/42500 [==============================] - 23s 545us/step - loss: 0.6243 - acc: 0.8249 - val_loss: 0.7299 - val_acc: 0.8031\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.68152\n",
      "Epoch 10/10\n",
      "42500/42500 [==============================] - 23s 551us/step - loss: 0.5943 - acc: 0.8369 - val_loss: 0.7915 - val_acc: 0.7985\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.68152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2003e9c0dd8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(filepath = 'weights_Transfer_learning.best.hdf5', verbose = 1, save_best_only = True)\n",
    "model.fit(features,y_train, epochs=10, batch_size=100, verbose=1,callbacks=[checkpoint], validation_split=0.15, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model weights that yielded best validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights_Transfer_learning.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model classification accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[0.7044107089042664, 0.7872]\n"
     ]
    }
   ],
   "source": [
    "score= model.evaluate(features_test,y_test,verbose=0)\n",
    "print(model.metrics_names)\n",
    "print(score)\n",
    "accuracy=100*score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 78.72\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
