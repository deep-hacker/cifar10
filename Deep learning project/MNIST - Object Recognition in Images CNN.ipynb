{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Load MNIST Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\train-images-idx3-ubyte.gz\n",
      "Extracting .\\train-labels-idx1-ubyte.gz\n",
      "Extracting .\\t10k-images-idx3-ubyte.gz\n",
      "Extracting .\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Define the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.validation.images.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 28, 28, 16)        80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 14, 14, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 7, 7, 64)          8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 500)               512500    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 527,926\n",
      "Trainable params: 527,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, AveragePooling2D\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(filters=64,kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation= 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 64s 1ms/step - loss: 0.2995 - acc: 0.9024 - val_loss: 0.0790 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07898, saving model to MNISTweightsCNN.best.hdf5\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 63s 1ms/step - loss: 0.0911 - acc: 0.9709 - val_loss: 0.0564 - val_acc: 0.9818\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.07898 to 0.05644, saving model to MNISTweightsCNN.best.hdf5\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 60s 1ms/step - loss: 0.0646 - acc: 0.9797 - val_loss: 0.0512 - val_acc: 0.9832\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05644 to 0.05123, saving model to MNISTweightsCNN.best.hdf5\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 57s 1ms/step - loss: 0.0526 - acc: 0.9834 - val_loss: 0.0390 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05123 to 0.03904, saving model to MNISTweightsCNN.best.hdf5\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 53s 970us/step - loss: 0.0396 - acc: 0.9875 - val_loss: 0.0277 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03595 to 0.02772, saving model to MNISTweightsCNN.best.hdf5\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 59s 1ms/step - loss: 0.0348 - acc: 0.9885 - val_loss: 0.0294 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02772\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 121s 2ms/step - loss: 0.0339 - acc: 0.9887 - val_loss: 0.0385 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02772\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 121s 2ms/step - loss: 0.0314 - acc: 0.9904 - val_loss: 0.0349 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02772\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 115s 2ms/step - loss: 0.0282 - acc: 0.9910 - val_loss: 0.0354 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02772\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(filepath = 'MNISTweightsCNN.best.hdf5', verbose = 1, save_best_only = True)\n",
    "history = model.fit(mnist.train.images,mnist.train.labels, epochs=10, batch_size=100, verbose=1,callbacks=[checkpoint], validation_data=(mnist.validation.images,mnist.validation.labels), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Load the model weights that yielded best validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('MNISTweightsCNN.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Evaluate model classification accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[0.030614228255581112, 0.9899]\n"
     ]
    }
   ],
   "source": [
    "score= model.evaluate(mnist.test.images,mnist.test.labels,verbose=0)\n",
    "print(model.metrics_names)\n",
    "print(score)\n",
    "accuracy=100*score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.99\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy:',accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
